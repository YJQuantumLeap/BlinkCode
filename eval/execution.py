
from typing import Dict
import os
import shutil
from utils import convert_html_to_image, process_figure_code, unsafe_execute_matplotlib_code, cal_evaluation_score, cal_evaluation_score, run_pdflatex, get_code, ReliabilityGuard, check_and_process_images, create_tempdir, time_limit, TimeoutException, swallow_io
import re
import json
import cairosvg
import fitz
from models.base_model import OpenAIModel


gpt4v_request = OpenAIModel(model_name="gpt-4-vision-preview").forward
gpt4o_request = OpenAIModel(model_name="gpt-4o-2024-05-13").forward

with open("prompt/evaluate_prompt.json", 'r') as f:
    evaluate_prompt = json.load(f)

# save_image_directory is used to save the image generated by the code
save_image_directory = 'tmp_images'


def check_result_is_correct(mllm_answer, ground_truth_answer, query, image_path, num=4):
    """check the mllm answer of vp is correct or not
    """
    query2 = evaluate_prompt["VP"].replace("{question}", query).replace(
        "{label}", ground_truth_answer).replace("{answer_to_evaluate}", mllm_answer)
    if os.path.exists(image_path) == False:
        raise ValueError("image_path does not exist")

    result_, content = gpt4o_request(query2, image_path1=image_path)
    if result_ != True:
        if num == 0:
            raise Exception(f"Error: {content}")
        else:
            return check_result_is_correct(mllm_answer, ground_truth_answer, query2, image_path, num-1)

    content = content.lower()
    content_split = content.split('\n')
    if len(content_split) < 2:
        raise ValueError("content less two line")

    if "true" in content_split[0] or "true" in content_split[1]:
        return True,  f"ground truth answer: {ground_truth_answer}, MLLM answer: {mllm_answer}\n\n check_result_is_correct_answer:" + f"query: {query}, response: {content}"
    else:
        return False, f"ground truth answer: {ground_truth_answer}, MLLM answer: {mllm_answer}\n\n check_result_is_correct_answer:" + f"query: {query}, response: {content}"


def evaluate_restructed(problem, code, timeout, result):
    """evaluate the code of webpage, matplotlib, svg, tikz by gpt-4-vision-preview and the image generated by the code is saved in save_image_directory
    """
    work_path = os.getcwd()
    with create_tempdir():
        now_path = os.getcwd()
        pre_image_path = os.path.join(
            work_path,  'data', problem['path'])  # the original image
        temp_image_path = os.path.join(
            now_path, str(problem['id']) + '.png')  # the image generated by the code
        save_image_directory_ = os.path.join(work_path,
                                             save_image_directory, problem['model'], problem['type'])
        os.makedirs(save_image_directory_, exist_ok=True)
        save_image_path = os.path.join(save_image_directory_,
            str(problem['id']) + '.png')
        prompt = evaluate_prompt[problem['type']]

        if code == '':
            result.append('Error: this code is empty!')
            result.append(f'score: 4 4 4')
            result.append(0)
            return

        if problem['type'] == 'Webpage':
            html_code = code
            html_path = os.path.join(
                now_path, f'{problem["id"]}.html')

            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_code)
            try:
                with time_limit(timeout):
                    convert_html_to_image(html_path, temp_image_path)
            except Exception as e:
                result.append(
                    f'Error: html code does not work properly 1, error {e}')
                result.append(f'score: 4 4 4')
                result.append(0)
                return
            if os.path.exists(temp_image_path) == False:
                result.append(f'Error: html code does not work properly 2')
                result.append(f'score: 4 4 4')
                result.append(0)
                return
            shutil.copy(temp_image_path, save_image_path)
        elif problem['type'] == 'Matplotlib':
            figure_code = code
            figure_code = process_figure_code(figure_code, temp_image_path)
            result_of_execution = unsafe_execute_matplotlib_code(figure_code)
            if result_of_execution != 'True' and os.path.exists(temp_image_path) == False:
                result.append(
                    f'matplotlib code execution error: {result_of_execution}')
                result.append(f'score: 4 4 4')
                result.append(0)
                return
            shutil.copy(temp_image_path, save_image_path)
        elif problem['type'] == 'SVG':
            svg_code = code
            svg_path = os.path.join(
                now_path, str(problem['id']) + '.svg')
            with open(svg_path, 'w', encoding='utf-8') as f:
                f.write(svg_code)
            try:
                with time_limit(3):
                    cairosvg.svg2png(
                        url=svg_path, write_to=temp_image_path, background_color="white")
            except Exception as e:
                result.append(
                    f'Error: svg code does not work properly 1, error :{e}')
                result.append(f'score: 4 4 4')
                result.append(0)
                return

            if os.path.exists(temp_image_path) == False:
                result.append(
                    f'The svg code worked out, but cannot produce image')
                result.append(f'score: 4 4 4')
                result.append(0)
                return
            shutil.copy(temp_image_path, save_image_path)
        elif problem['type'] == 'TikZ':
            tikz_code = code
            tikz_path = os.path.join(
                now_path, str(problem['id']) + '.tex')
            with open(tikz_path, 'w', encoding='utf-8') as f:
                f.write(tikz_code)
            try:
                with time_limit(12):
                    temp_pdf_path = os.path.join(
                        now_path, str(problem['id']) + '.pdf')
                    result_tikz = run_pdflatex(tikz_path, now_path)
                    if os.path.exists(temp_pdf_path) == False:
                        raise Exception(result_tikz)
                    pdf_document = fitz.open(temp_pdf_path)
                    for page_num in range(len(pdf_document)):
                        page = pdf_document.load_page(page_num)
                        pix = page.get_pixmap()
                        pix.save(temp_image_path)
            except Exception as e:
                result.append(
                    f'Error: tikz code does not work properly 1 error:{e}')
                result.append(f'score: 4 4 4')
                result.append(0)
                return
            if os.path.exists(temp_image_path) == False:
                result.append(f'Error: tikz code does not work properly 2')
                result.append(f'score: 4 4 4')
                result.append(0)
                return
            shutil.copy(temp_image_path, save_image_path)
        prompt = prompt + '\n' + \
            "You must answer this question according to the scoring format(The first line contains only three numbers separated by spaces)."
        check_and_process_images(temp_image_path)
        model_result, answer = gpt4v_request(
            prompt, image_path1=pre_image_path, image_path2=temp_image_path)
        if model_result == False:
            result.append(f'evaluation model error: {answer}')
            result.append(f'score: 4 4 4')
            result.append(0)
            result.append(answer)
            return
        parts = re.split(r'\s+', answer)
        try:
            numbers = [int(x) for x in parts[:3]]
            score = cal_evaluation_score(numbers)
            if type(score) != int:
                raise Exception
            result.append("True")
            result.append(f'score: {numbers[0]} {numbers[1]} {numbers[2]}')
            result.append(score)
            result.append(answer)
            return
        except:
            result.append(
                f'evaluation model error: answer format does not match! \nanswer: {answer}')
            result.append(f'score: 4 4 4')
            result.append(0)
            result.append(answer)
            return


def unsafe_execute_python(problem, code, timeout, result):
    """unsafe execute the python code
    """
    if code == "":
        result.append(f"code empty!")
        return
    with create_tempdir():
        with ReliabilityGuard():
            # Construct the check program and run it.
            if problem['type'] == 'MBPP-V':
                check_program = (
                    code + "\n" +
                    problem['evaluation_function'] + "\n" +
                    f"check({problem['function_name'].split('(')[0]})"
                )
            else:
                check_program = (
                    code + "\n" +
                    problem['evaluation_function'] + "\n" +
                    f"check({problem['function_name']})"
                )
            try:
                exec_globals = {}
                with swallow_io():
                    with time_limit(timeout):
                        exec(check_program, exec_globals)
                result.append("passed")
            except TimeoutException:
                result.append("timed out")
            except AssertionError as e:
                result.append(f"assertion error: {e.__repr__()}")
            except BaseException as e:
                result.append(f"failed: {e.__repr__()}")


def unsafe_execute_viper_code(problem, code, timeout, result, viper_exec_code):
    """unsafe execute the viper code
    """
    img_path = os.path.join(os.getcwd(), 'data', problem['path'])
    exec_result = viper_exec_code(code, img_path, timeout)
    if "Error:" in exec_result:
        result.append(exec_result)
    else:
        isTrue, content = check_result_is_correct(
            exec_result, problem['reference_answer'], problem['query'], img_path)
        if isTrue:
            result.append("passed")
            result.append(content)
        else:
            result.append(
                f"Expect answer {problem['reference_answer']}, but get answer {exec_result}")
            result.append(content)


def check_correctness(problem: Dict, code: str, timeout: int, viper_exec_code=None) -> Dict:
    """check the correctness of the code
    """
    result = []
    if problem['type'] in ['Webpage', 'Matplotlib', 'SVG', 'TikZ']:
        evaluate_restructed(problem, code, timeout, result)
    elif problem['type'] in ['HumanEval-V', 'MBPP-V', 'GSM8K-V', 'MATH-V']:
        unsafe_execute_python(problem, code, timeout, result)
    else:
        unsafe_execute_viper_code(
            problem, code, timeout, result, viper_exec_code)
    if result == []:
        raise ValueError("result is empty!")
    if problem['type'] in ['HumanEval-V', 'MBPP-V', 'GSM8K-V', 'MATH-V', 'VP']:
        error_type = ""
        if result[0] != "passed":
            error_type = result[0]
        else:
            error_type = ''
        if problem['type'] == 'VP' and len(result) > 1:
            error_type += "\nEvaluation results of MLLM answers and real answers:" + \
                result[1]
        return_dict = dict(
            task_id=problem["id"],
            type=problem["type"],
            passed=result[0] == "passed",
            error_type=error_type,
        )
    else:
        MLLM_evaluate = {}
        if result[0] == 'True' or result[0] == 'Error, answer format does not match!':
            MLLM_evaluate = result[3]
        return_dict = dict(
            task_id=problem["id"],
            type=problem["type"],
            score=result[2],
            Score_for_each_item=result[1],
            MLLM_evaluate=MLLM_evaluate,
            error_type=result[0],
        )
    return return_dict
